# The CMDdata class needs to be able to hold however many filters are available to do statistics with...or however many filters are desired to do statistics with.
import numpy as np
import pandas as pd
import os
from processing import columnread as cread
from processing import userinteract as user

class cmdset(object):
    
    def __init__(self, kind = 'data'):



        def loadData(readmode='data'):


             # root_dir should be /cmdfit
            root_dir = os.path.dirname(os.path.abspath(__file__))

            if readmode == 'data':
                data_dir = root_dir + '/data'
                print('SELECT DESIRED DATA PATH:\n(Reading from {:s}.)'.format(data_dir))
                specific_data_dir = data_dir + user.select_a_dir(data_dir,type_flag = 1)
                data_file = specific_data_dir + user.select_a_dir(specific_data_dir, 2)

            elif readmode == 'model':
                cmd_model_path = root_dir + '/model'
                print('SELECT DESIRED MODEL PATH:\n(Reading from {:s}.)'.format(cmd_model_path))
                specific_model_path = cmd_model_path + user.select_a_dir(cmd_model_path,type_flag = 1)
                selected_run_path = specific_model_path + user.select_a_dir(specific_model_path,type_flag = 1)
                data_file = selected_run_path + user.select_a_dir(selected_run_path,type_flag = 2)
            
            else:
                print('Usage:\ncmdset(kind = ...), where \'...\' is either \'data\' if reading from a data file or \'model\' if reading from a model file.')

            # Ask which column is relevant.
            # Store the column header name
            # Store the data in the column.
            # Do this until told to stop
            # Put data in a data frame with column names as the keys
            # Also put something in to let user see the keys on request.

            dataMatrix = []
            uncertMatrix = []
            dataNames = []
            uncertNames = []
            keepgoing = True

            while keepgoing:
                dataCol, dataName = cread.assign_data(data_file, mode=readmode, returnNames=True)
                
                # Ask about supplying uncertainty values from the data table:
                if readmode == 'data':
                    print('\nSELECT UNCERTAINTIES CORRESPONDING TO COLUMN {:s}.'.format(dataName))
                    # Ask if uncertainties should be loaded from the data file, or generated in some other way.
                    response = user.ask_for_specific_input('LOAD FROM {:s}? (If \'n\', a nominal +/-0.1 dex will be used.)'.format(data_file.split('/')[-1]), 'y', 'n')
                    if response == 'y':
                        uncertCol, uncertName = cread.assign_data(data_file, mode=readmode, returnNames=True)
                    else:
                        # In the future maybe give some options for users to select how they want to generate uncertainties if the data doesn't supply them.
                        # This nominal value is based on my reading of Jorgensen & Lindegren 2005.
                        uncertCol = [0.1] * len(dataCol)
                        uncertName = dataName + 'err'

                    uncertMatrix.append(uncertCol)
                    uncertNames.append(uncertName)
                
                dataMatrix.append(dataCol)
                dataNames.append(dataName)

                response = user.ask_for_specific_input('\n================================\nWould you like to enter another filter as data? ', 'y', 'n')
                if  response == 'y':
                    continue
                else:
                    keepgoing = False

            # Now we have a matrix containing all selected magnitudes; each magnitude set is stored columnwise in dataMatrix and the respective column names are stored columnwise in dataNames.
            # Place the data into a Pandas data frame for easy reference:

            dataMatrix = np.array(dataMatrix)
            dataNames = np.array(dataNames)

            loadedData = pd.DataFrame(dataMatrix.T, columns = dataNames)

            if readmode == 'data':
                uncertMatrix = np.array(uncertMatrix)
                uncerNames = np.array(uncertNames)
                loadedUncert = pd.DataFrame(uncertMatrix.T, columns = uncertNames)

                return loadedData, loadedUncert

            return loadedData

        # Attributes: 
        if kind == 'data':
            self.magnitudes, self.uncertainties = loadData(readmode = 'data')
        
        elif kind == 'model':
            self.magnitudes = loadData(readmode = 'model')
            # Also load info on other params...

        self.kind = kind
     
    # Utility functions:
    def makeBands(self):
          
        # This function will only operate if the cmdset object has a kind equal to 'data'.
        if self.kind == 'model':
            print('\nERROR: This cmdset is a model and makeBands() will only operate on data sets.\n')
            return
        
        # Iterates through columns of the magnitude data frame:
        bandmags = [] 
        for band in self.magnitudes:
            bandmags.append(self.magnitudes[band].values)
       
        # Same, but for uncertainties:
        banduncert = []
        for banderr in self.uncertainties:
            banduncert.append(self.uncertainties[banderr].values)
        
        # Conglomerate into a larger list with column 1 holding the list of magnitude arrays and column 2 holding the list of uncertainty arrays:
        banddata = [bandmags, banduncert]

        return banddata
       
